{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl9ZpNSMpMYw"
      },
      "source": [
        "#Python Chess Engine Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwsmQl0-poVV"
      },
      "source": [
        "**libraries**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BFciLyCHgTvO"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_3vxIeTp1MN"
      },
      "source": [
        "**data**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVmgs9pbp-SU"
      },
      "source": [
        "import the chess games dataset from github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLQiryJKW6xP",
        "outputId": "70cc3a02-6f26-42d2-ac22-d0c768abf0cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'chess-games-dataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/iAmEthanMai/chess-games-dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xSiXhMHNggxe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "path_fischer = './chess-games-dataset/Data/CSV_FISCHER'\n",
        "path_morphy = './chess-games-dataset/Data/CSV_MORPHY'\n",
        "path_capablanca = './chess-games-dataset/Data/CSV_CAPABLANCA'\n",
        "\n",
        "files_fischer = glob.glob(path_fischer + \"/*.csv\")\n",
        "#files_morphy = glob.glob(path_morphy + \"/*.csv\")\n",
        "#files_capablanca = glob.glob(path_capablanca + \"/*.csv\")\n",
        "\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in files_fischer:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "train = pd.concat(li, axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hNx5FPleuUpS"
      },
      "outputs": [],
      "source": [
        "train = shuffle(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slh5bdzWgqRv",
        "outputId": "1cbd7a27-0f2a-4aae-f3dc-beca40ca0e50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(830376, 193)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "nbD_g8mSqst7",
        "outputId": "249dfff6-1dcc-4924-ada1-65c5894bebdd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a1</th>\n",
              "      <th>b1</th>\n",
              "      <th>c1</th>\n",
              "      <th>d1</th>\n",
              "      <th>e1</th>\n",
              "      <th>f1</th>\n",
              "      <th>g1</th>\n",
              "      <th>h1</th>\n",
              "      <th>a2</th>\n",
              "      <th>b2</th>\n",
              "      <th>...</th>\n",
              "      <th>to_h7</th>\n",
              "      <th>to_a8</th>\n",
              "      <th>to_b8</th>\n",
              "      <th>to_c8</th>\n",
              "      <th>to_d8</th>\n",
              "      <th>to_e8</th>\n",
              "      <th>to_f8</th>\n",
              "      <th>to_g8</th>\n",
              "      <th>to_h8</th>\n",
              "      <th>good_move</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>736412</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>K</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223012</th>\n",
              "      <td>R</td>\n",
              "      <td>N</td>\n",
              "      <td>B</td>\n",
              "      <td>Q</td>\n",
              "      <td>K</td>\n",
              "      <td>B</td>\n",
              "      <td>N</td>\n",
              "      <td>R</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78395</th>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>R</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277830</th>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>R</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671736</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>K</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 193 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         a1   b1   c1   d1   e1   f1 g1   h1   a2 b2  ... to_h7 to_a8 to_b8  \\\n",
              "736412  NaN  NaN    K    R  NaN  NaN  R  NaN    P  P  ...   0.0   0.0   0.0   \n",
              "223012    R    N    B    Q    K    B  N    R    P  P  ...   0.0   0.0   0.0   \n",
              "78395     R  NaN  NaN    Q  NaN    R  K  NaN    P  P  ...   0.0   0.0   0.0   \n",
              "277830    R  NaN  NaN  NaN  NaN    R  K  NaN  NaN  P  ...   0.0   0.0   0.0   \n",
              "671736  NaN  NaN  NaN  NaN  NaN    Q  B  NaN  NaN  K  ...   0.0   0.0   0.0   \n",
              "\n",
              "       to_c8 to_d8 to_e8 to_f8 to_g8 to_h8 good_move  \n",
              "736412   0.0   1.0   0.0   0.0   0.0   0.0     False  \n",
              "223012   0.0   0.0   0.0   0.0   0.0   0.0     False  \n",
              "78395    0.0   0.0   0.0   0.0   0.0   0.0     False  \n",
              "277830   0.0   0.0   0.0   0.0   0.0   0.0     False  \n",
              "671736   0.0   0.0   0.0   0.0   0.0   0.0     False  \n",
              "\n",
              "[5 rows x 193 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eS-CxibqwBN"
      },
      "source": [
        "**features**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xWLjGXv-g5Ph"
      },
      "outputs": [],
      "source": [
        "features = list(train.iloc[:, 0:192].columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-jz-tMDPg8TY"
      },
      "outputs": [],
      "source": [
        "X = train[features]\n",
        "y = train['good_move']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x5dhguuhDhM",
        "outputId": "eec30ea8-343f-46f5-8d7d-6439c022da5d"
      },
      "outputs": [],
      "source": [
        "categorical_columns = list(X.iloc[:, 0:63].columns)\n",
        "numerical_columns = list(X.iloc[:, 64:192].columns)\n",
        "feature_columns = []\n",
        "\n",
        "for feature_name in categorical_columns:\n",
        "  vocabulary = X[feature_name].unique()\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "\n",
        "for feature_name in numerical_columns:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype = tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L8CbTnMsCKD"
      },
      "source": [
        "**input function**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0z_ETx3yhInr"
      },
      "outputs": [],
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs = 10, shuffle = True, batch_size = 32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjsegLZzupXr"
      },
      "source": [
        "**split data into batches**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "x2YoZFeFux0W"
      },
      "outputs": [],
      "source": [
        "def split_into_batches(df, batch_size=100000):\n",
        "  nb_rows = len(df.index)\n",
        "  intervals = []\n",
        "\n",
        "  for i in range(0, nb_rows + 1, batch_size):\n",
        "    intervals.append(i)\n",
        "\n",
        "  if(intervals[-1] != nb_rows):\n",
        "    intervals.append(nb_rows)\n",
        "\n",
        "  batches_X = []\n",
        "  batches_y = []\n",
        "\n",
        "  for i in range(0, len(intervals) - 1):\n",
        "    batches_X.append(train.iloc[intervals[i]:intervals[i + 1], :][features])\n",
        "    batches_y.append(train.iloc[intervals[i]:intervals[i + 1], :]['good_move'])\n",
        "\n",
        "  return batches_X, batches_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "e_bCFyfXzNgI"
      },
      "outputs": [],
      "source": [
        "batches_X, batches_y = split_into_batches(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p312bOtf3gry"
      },
      "source": [
        "**model**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40Z0jdfnhQKp",
        "outputId": "facff005-24c0-4db6-c0f8-88a14ea07667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './estimator/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ],
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns = feature_columns, model_dir='./estimator/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtu3FPLN3mx5"
      },
      "source": [
        "**train model**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRQFWso4zRj-"
      },
      "outputs": [],
      "source": [
        "input_functions = []\n",
        "for df_X, df_y in zip(batches_X, batches_y):\n",
        "  input_functions.append(make_input_fn(df_X, df_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlQNB-o8Zh_J",
        "outputId": "19572347-611f-4cd2-de9b-27de371ea45d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(input_functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8m7e7OV3Ol6",
        "outputId": "c61e2b36-9d20-4259-ef4d-21d6704f6bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "<======================================== NEW BATCH ========================================>\n",
            "Batch: 1\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Expected binary or unicode string, got nan",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\util\\structure.py:104\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     spec \u001b[39m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[39m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[39m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\util\\structure.py:507\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    504\u001b[0m     logging\u001b[39m.\u001b[39mvlog(\n\u001b[0;32m    505\u001b[0m         \u001b[39m3\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to convert \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m to tensor: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mtype\u001b[39m(element)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, e))\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not build a `TypeSpec` for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    508\u001b[0m     element,\n\u001b[0;32m    509\u001b[0m     \u001b[39mtype\u001b[39m(element)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n",
            "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 736412    NaN\n223012      R\n78395       R\n277830      R\n671736    NaN\n         ... \n191155      R\n136138      R\n406132      R\n438643    NaN\n96876       R\nName: a1, Length: 100000, dtype: object with type Series",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\loutl\\OneDrive\\Documents\\GitHub\\Chess-Engine\\train_chess_engine.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBatch: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   i \u001b[39m=\u001b[39m i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   linear_est\u001b[39m.\u001b[39;49mtrain(input_function)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# save the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m serving_input_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mexport\u001b[39m.\u001b[39mbuild_parsing_serving_input_receiver_fn(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m   tf\u001b[39m.\u001b[39mfeature_column\u001b[39m.\u001b[39mmake_parse_example_spec(feature_columns))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    357\u001b[0m hooks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[0;32m    359\u001b[0m saving_listeners \u001b[39m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[1;32m--> 360\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model(input_fn, hooks, saving_listeners)\n\u001b[0;32m    361\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoss for final step: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[0;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1188\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[0;32m   1187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1188\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model_default(input_fn, hooks, saving_listeners)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1214\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1210\u001b[0m \u001b[39mif\u001b[39;00m global_step_tensor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m   training_util\u001b[39m.\u001b[39m_get_or_create_global_step_read(g)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m features, labels, input_hooks \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_features_and_labels_from_input_fn(input_fn, ModeKeys\u001b[39m.\u001b[39;49mTRAIN))\n\u001b[0;32m   1215\u001b[0m worker_hooks\u001b[39m.\u001b[39mextend(input_hooks)\n\u001b[0;32m   1216\u001b[0m estimator_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_model_fn(features, labels, ModeKeys\u001b[39m.\u001b[39mTRAIN,\n\u001b[0;32m   1217\u001b[0m                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1050\u001b[0m, in \u001b[0;36mEstimator._get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_features_and_labels_from_input_fn\u001b[39m(\u001b[39mself\u001b[39m, input_fn, mode):\n\u001b[0;32m   1048\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m   \u001b[39mreturn\u001b[39;00m estimator_util\u001b[39m.\u001b[39mparse_input_fn_result(\n\u001b[1;32m-> 1050\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_input_fn(input_fn, mode))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1143\u001b[0m, in \u001b[0;36mEstimator._call_input_fn\u001b[1;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[0;32m   1141\u001b[0m   kwargs[\u001b[39m'\u001b[39m\u001b[39minput_context\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m input_context\n\u001b[0;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/cpu:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m-> 1143\u001b[0m   \u001b[39mreturn\u001b[39;00m input_fn(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32mc:\\Users\\loutl\\OneDrive\\Documents\\GitHub\\Chess-Engine\\train_chess_engine.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minput_function\u001b[39m():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices((\u001b[39mdict\u001b[39;49m(data_df), label_df))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loutl/OneDrive/Documents/GitHub/Chess-Engine/train_chess_engine.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mshuffle(\u001b[39m1000\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:831\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[39m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_tensor_slices_op\n\u001b[1;32m--> 831\u001b[0m \u001b[39mreturn\u001b[39;00m from_tensor_slices_op\u001b[39m.\u001b[39;49m_from_tensor_slices(tensors, name)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 25\u001b[0m   \u001b[39mreturn\u001b[39;00m _TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, element, is_files\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m   element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mnormalize_element(element)\n\u001b[0;32m     34\u001b[0m   batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m     35\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\util\\structure.py:109\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    104\u001b[0m     spec \u001b[39m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[39m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[39m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m   normalized_components\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 109\u001b[0m       ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomponent_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m i))\n\u001b[0;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m   \u001b[39m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m   \u001b[39m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m   \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDatasetSpec\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:1443\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[1;32m-> 1443\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[0;32m   1444\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[0;32m   1445\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    323\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\constant_op.py:277\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    279\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:1008\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m   1005\u001b[0m g \u001b[39m=\u001b[39m get_default_graph()\n\u001b[0;32m   1006\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n\u001b[0;32m   1007\u001b[0m tensor_value\u001b[39m.\u001b[39mtensor\u001b[39m.\u001b[39mCopyFrom(\n\u001b[1;32m-> 1008\u001b[0m     tensor_util\u001b[39m.\u001b[39;49mmake_tensor_proto(\n\u001b[0;32m   1009\u001b[0m         value, dtype\u001b[39m=\u001b[39;49mdtype, shape\u001b[39m=\u001b[39;49mshape, verify_shape\u001b[39m=\u001b[39;49mverify_shape,\n\u001b[0;32m   1010\u001b[0m         allow_broadcast\u001b[39m=\u001b[39;49mallow_broadcast))\n\u001b[0;32m   1011\u001b[0m dtype_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mtensor_value\u001b[39m.\u001b[39mtensor\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m   1012\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: tensor_value, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value}\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:623\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[39mif\u001b[39;00m append_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    622\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mElement type not supported in TensorProto: \u001b[39m\u001b[39m{\u001b[39;00mnumpy_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 623\u001b[0m append_fn(tensor_proto, proto_values)\n\u001b[0;32m    625\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_proto\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:190\u001b[0m, in \u001b[0;36mSlowAppendObjectArrayToTensorProto\u001b[1;34m(tensor_proto, proto_values)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSlowAppendObjectArrayToTensorProto\u001b[39m(tensor_proto, proto_values):\n\u001b[1;32m--> 190\u001b[0m   tensor_proto\u001b[39m.\u001b[39mstring_val\u001b[39m.\u001b[39mextend([compat\u001b[39m.\u001b[39;49mas_bytes(x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m proto_values])\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:190\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSlowAppendObjectArrayToTensorProto\u001b[39m(tensor_proto, proto_values):\n\u001b[1;32m--> 190\u001b[0m   tensor_proto\u001b[39m.\u001b[39mstring_val\u001b[39m.\u001b[39mextend([compat\u001b[39m.\u001b[39;49mas_bytes(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m proto_values])\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\compat.py:85\u001b[0m, in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     83\u001b[0m   \u001b[39mreturn\u001b[39;00m bytes_or_text\n\u001b[0;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mExpected binary or unicode string, got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m     86\u001b[0m                   (bytes_or_text,))\n",
            "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got nan"
          ]
        }
      ],
      "source": [
        "# train the model on all the input functions\n",
        "i = 1\n",
        "j = 1\n",
        "\n",
        "for input_function in input_functions:\n",
        "  j += 1\n",
        "\n",
        "print(j)\n",
        "\n",
        "for input_function in input_functions:\n",
        "  print('<======================================== NEW BATCH ========================================>')\n",
        "  print('Batch: ' + str(i))\n",
        "  i = i + 1\n",
        "  linear_est.train(input_function)\n",
        "\n",
        "\n",
        "# save the model\n",
        "serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "  tf.feature_column.make_parse_example_spec(feature_columns))\n",
        "\n",
        "estimator_base_path = './estimator/'\n",
        "estimator_path = linear_est.export_saved_model(estimator_base_path, serving_input_fn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
